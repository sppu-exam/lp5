{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Write your CUDA code to a file\n",
        "code = \"\"\"\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "using namespace std;\n",
        "\n",
        "__global__ void matrixMulCUDA(int* A, int* B, int* C, int N) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (row < N && col < N) {\n",
        "        int value = 0;\n",
        "        for (int i = 0; i < N; i++) {\n",
        "            value += A[row * N + i] * B[i * N + col];\n",
        "        }\n",
        "        C[row * N + col] = value;\n",
        "    }\n",
        "}\n",
        "\n",
        "void printMatrix(int* matrix, int N) {\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            cout << matrix[i * N + j] << \" \";\n",
        "        }\n",
        "        cout << endl;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int N = 2;\n",
        "\n",
        "    int h_A[4] = {1, 2, 3, 4}; // Matrix A\n",
        "    int h_B[4] = {5, 6, 7, 8}; // Matrix B\n",
        "    int h_C[4];\n",
        "\n",
        "    int *d_A, *d_B, *d_C;\n",
        "    cudaMalloc(&d_A, N * N * sizeof(int));\n",
        "    cudaMalloc(&d_B, N * N * sizeof(int));\n",
        "    cudaMalloc(&d_C, N * N * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 threadsPerBlock(16, 16);\n",
        "    dim3 numBlocks((N + 15) / 16, (N + 15) / 16);\n",
        "\n",
        "    matrixMulCUDA<<<numBlocks, threadsPerBlock>>>(d_A, d_B, d_C, N);\n",
        "\n",
        "    cudaError_t err = cudaGetLastError();\n",
        "    if (err != cudaSuccess) {\n",
        "        cout << \"CUDA error: \" << cudaGetErrorString(err) << endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(h_C, d_C, N * N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cout << \"Result matrix C (A * B):\" << endl;\n",
        "    printMatrix(h_C, N);\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with open(\"matrix_mul.cu\", \"w\") as f:\n",
        "    f.write(code)\n"
      ],
      "metadata": {
        "id": "w2363CF99-0V"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qmi8qOpw2vQ2"
      },
      "outputs": [],
      "source": [
        "!nvcc -gencode=arch=compute_60,code=sm_60 \\\n",
        "      -gencode=arch=compute_70,code=sm_70 \\\n",
        "      -gencode=arch=compute_75,code=sm_75 \\\n",
        "      -o matrix_mul matrix_mul.cu\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./matrix_mul\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0puoQEk-Hc8",
        "outputId": "90f14885-7b90-4849-d75d-ef4e74184f40"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result matrix C (A * B):\n",
            "19 22 \n",
            "43 50 \n"
          ]
        }
      ]
    }
  ]
}